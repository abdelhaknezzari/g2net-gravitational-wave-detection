---
title: "README"
output: md_document
---

# Kaggle's competition:
[](https://www.kaggle.com/c/g2net-gravitational-wave-detection/overview)
The competition is about detecting gravitational waves in three signals coming from three interferometre

We are interested in this competition, as the waves looks like a sound, and we can apply some sound engineering technics, and some digital signal processing to extract some features from the data, before apply some deep learning to the models to train to predict the class of the wave
- '0': if there is no sound analysis detected
- '1': if there is one

the signal consist of three waves recording in three locations:
- LIGO Hanford,
- LIGO Livingston
- Virgo

the challenge of this data is that it needs many disciplines including physics, digital signal processing, sound engineering and data science, in my previous studies when I was junger, I studied some electrical engeneering, it is a vey nice opportunity to remember some lessons learned at that time,


it is kind of dream to work with such data, for a developer like me, where getting data at work is some times impossible due to some confidentiality closes, where we can not freely to get the data to apply some data science algorithms

we will use sound analysis to study these gravitational waves,

Nice book about sound analysis using R [](https://link.springer.com/book/10.1007/978-3-319-77647-7), it shows many examples for plotting spectorgrams


We group the function we build in [file](functions.R)
```{r setup, include=FALSE, echo = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)

source('functions.R')
```

## R Markdown

Read data from the npy file, and plot them as time series with ggplot, every npy file contains the three waves

```{r  }
library(RcppCNPy)
library(tidyverse)
library(tuneR)
library(seewave)

"00000e74ad.npy" %>% npyLoad() -> imat

imat %>%
  t() %>%
  as.data.frame() %>%
  rename( x =V1 , y = V2 , z = V3) %>%
  add_column( index = 1:(imat %>% ncol()) ) %>%
  gather( key, value , -index ) %>%
  ggplot( aes (y = value, x = index) ) +
  geom_line() +
  facet_grid(rows = vars(key)) +
  xlab("Time") + ylab("Intensity")


```



we plot the spectrogram of the time series wave, and we limit the frequecy boundary of the plot from 0 to 0.03 khz

```{r  FrequencyAnlysis}
"00001f4945.npy" %>% readWaveFromNpy(1)  %>% spec( flim = c(0,0.03) )


```





## Including Plots

You can also embed plots, for example:

```{r  TimeFrequency1}
"00001f4945.npy" %>% spectreTest()
```

similar to [example](https://rug.mnhn.fr/seewave/spec.html)
the code was copied form the above source, we have refactored it into different functions, to avoid occyping the memory with temporarly useless data
the result we are looking is to plot some graphs.

```{r TimeFrequency2}
 "00001f4945.npy" %>% readWaveFromNpy(2) %>% showPlots()

```


# shiny app for spectral analysis:
we use shiny applications in this project to explore visually the differnt parameters of the R functions and algorithms, this allow to find quickly the right tunning, and also understand the effect of every parameter, we use drop down list with different possible parameters, as well silders,
can be found in [folder](spectralAnalysisShinyApp)
![](otherPictures/ShinyApplication1.JPG)



# MFCC coefficients:


Calculate Frequency conversion and Filtering:
will apply some sound technique analysis, as frequencies domain is closer

```{r waveAuditorySpectrumScale}
"00001f4945.npy" %>% readWaveFromNpy(1) %>% scaleAndPlotAudSpecToMelFrequencies()
"00001f4945.npy" %>% readWaveFromNpy(2) %>% scaleAndPlotAudSpecToMelFrequencies()
"00001f4945.npy" %>% readWaveFromNpy(3) %>% scaleAndPlotAudSpecToMelFrequencies()

```


Cepstral Coefficients

```{r Cepstral image}

"00001f4945.npy" %>% readWaveFromNpy(1) %>% cepstralCoefs() %>% .$cep %>% image()
"00001f4945.npy" %>% readWaveFromNpy(2) %>% cepstralCoefs() %>% .$cep %>% image()
"00001f4945.npy" %>% readWaveFromNpy(3) %>% cepstralCoefs() %>% .$cep %>% image()

```
scale and plot

```{r scaleAndPlotCepstralCoefs}



"00001f4945.npy" %>% readWaveFromNpy(1) %>% scaleAndPlotCepstralCoefs()
"00001f4945.npy" %>% readWaveFromNpy(2) %>% scaleAndPlotCepstralCoefs()
"00001f4945.npy" %>% readWaveFromNpy(3) %>% scaleAndPlotCepstralCoefs()

```

MFCC coeficients


```{r calculate mfcc and plot image}


"00001f4945.npy" %>% readWaveFromNpy(1) %>% mfccCoefs() %>% image()
"00001f4945.npy" %>% readWaveFromNpy(2) %>% mfccCoefs() %>% image()
"00001f4945.npy" %>% readWaveFromNpy(3) %>% mfccCoefs() %>% image()
```

use melfcc function from tuneR package to calculate the coeficients

```{r iamgesMfcc}


"00001f4945.npy" %>% readWaveFromNpy(1) %>% mfccCoefs2() %>% .$cepstra %>% image()
"00001f4945.npy" %>% readWaveFromNpy(2) %>% mfccCoefs2() %>% .$cepstra %>% image()
"00001f4945.npy" %>% readWaveFromNpy(3) %>% mfccCoefs2() %>% .$cepstra %>% image()

```


Scale MFCC 13 coefficients and time to original and plot values in gery scale:

```{r scalePlotMfcc }


"00001f4945.npy" %>% readWaveFromNpy(1) %>% scalePlotMfcc()
"00001f4945.npy" %>% readWaveFromNpy(2) %>% scalePlotMfcc()
"00001f4945.npy" %>% readWaveFromNpy(3) %>% scalePlotMfcc()

```


Use ggplot for the graphs 'geom_raster'

```{r ggplotMFCC }
"00001f4945.npy" %>% readWaveFromNpy(1)   %>% ggplotMFCC()
```

Generate csv file with name of .npy files, with their paths and category type (1 : wave detected, 0: wave not detected )
```{r genrateCSVFileForWavesInfo, eval = FALSE}

"../machineLearningData/gravitationalWaves/train" %>%
        list.files( recursive = T,full.names = T, include.dirs = F) %>%
        as_tibble() %>%
        mutate( id = value %>% str_sub(55) ) %>%
        rename(filePath = value) %>%
        inner_join(
                "../machineLearningData/gravitationalWaves/train/ing_labels.csv" %>%
                        read.csv() %>%
                        as_tibble() %>%
                        mutate(id = paste0(id, ".npy") )
        ) %>%
        write.csv( file = "../machineLearningData/gravitationalWaves/train/file_labels.csv")

```

Produce animation of images of time frequency graphs using sample of gravitational waves are detected, we will try with animation to detect or see any feature from the data visual,
the first sequence of MFCC coefficients will be with only class data '1', then class '0' and finally we produce a sequence switching between class 1 and class 0, so to detect any difference visually as said.


Sequence of 20 images of class 1, we store them in [folder](otherPictures/coefficientsClass1):
```{r imagesClass1, eval = FALSE , echo = FALSE}

for( index in 1:20 ){
  "../machineLearningData/gravitationalWaves/train/file_labels.csv" %>%
    plotMFCC3Waves( 1 ) %>%
    ggsave( filename = sprintf("otherPictures/coefficientsClass1/coefficients%s.PNG", index),
            device = "png")
}


```

[](https://www.nagraj.net/notes/gifs-in-r/)


We produce the animation for the 20 images:

```{r animationClass1, eval = FALSE}
"otherPictures/coefficientsClass1" %>% animateMFCCCoefPlots(waveClass = 1)
```

We can show the produced animation
![](otherPictures/animations/animationCoeficientsClass1.gif)




we produce also images of coefficients of class 0, and we store them in [folder](otherPictures/coefficientsClass0):
```{r  produceImagesOfClass0, echo = FALSE,eval = FALSE}

for( index in 1:20 ){
  "../machineLearningData/gravitationalWaves/train/file_labels.csv" %>%
    plotMFCC3Waves( 0 ) %>%
    ggsave( filename = sprintf("otherPictures/coefficientsClass0/coefficients%s.PNG", index),
            device = "png")
}


```


we produce animation with 5 of produced images:

```{r animationClasse_0, eval = FALSE}
"otherPictures/coefficientsClass0" %>% animateMFCCCoefPlots(waveClass = 0)

```

We can show the produced animation
![](otherPictures/animations/animationCoeficientsClass1.gif)


let's produce animation with mix of coefficients pictures for class: '1' and '0'

```{r  animationClasse_1_and_0, eval = FALSE}
 "otherPictures/coefficientsClass0" %>%
  list.files(full.names = TRUE) %>%
  .[1:3] %>%
  rbind( "otherPictures/coefficientsClass1" %>% list.files(full.names = TRUE) %>% .[1:3] ) %>%
  c(.) %>%
  savePicturesAsAnimation( waveClass = 10 )
```

the animation of two classes 1 and 0 ( we used 3 images of each class)
![](otherPictures/animations/animationCoeficientsClass10.gif)



# shiny application for MFCC coefficients:
to understand the different parterres of MFCC calculation, we build another small shinny application:
- the user can change the parameters to see a better visualization
- to find suitable values, of the algorithm that we can use later
the application is located at [folder](mfccAnalysisShinyApp) it can run with file 'run.R'

this is a screenshot of the application, to see how it looks like:
![](otherPictures/ShinyApplicatio2.JPG)




# Reduce dimensions of MFCC matrix for better visualization
Visually it is hard to see the difference between the waves containing gravitation and the others, even with the animations techniques, it is still undistinguished,

let's do more:
- we calculate the MFCC coefficients with suitable parameters found with shiny application
- repeat the above step for many waves
- reduce the dimension of the MFCC matrices using PCA
- plot the scatter plot that show in two different colors the two classes of data
this will be a good indicator whether MFCC features can be used to train models



We take randomly a given number of waves for example 100 from both classes of the data, we do the following transformations for the data:
- Read the wave data
- Calculate MFCC matrix of dimension 19 x 64 ( number of coefficients is 19, window length is 64 for the signal)
- we convert the every matrix of signals to one vector of 1216
- perform principal component analysis for both samples of data, matrix of ( 200 x 1216 )
- take the two most significant vectors of resulted PCA
- plot a scatter plot with different colors for the data classes




```{r }


```



```{r }
getSamleOfMixClasses(1000 , 1 )%>% ggplot( aes( x = PC1, y = PC2 ) ) + geom_point( aes( colour = target)  )

```


```{r }
getSamleOfMixClasses(1000 , 2 )%>% ggplot( aes( x = PC1, y = PC2 ) ) + geom_point( aes( colour = target)  )

```


```{r }
getSamleOfMixClasses(1000 , 3 )%>% ggplot( aes( x = PC1, y = PC2 ) ) + geom_point( aes( colour = target)  )

```




for better visualization we tsne instead of PCA

```{r }



getSamleOfMixClassesTsne( 1000 , 1 , maxDim = 2 ) %>% ggplot( aes( x = V1, y = V2 ) ) + geom_point( aes( colour = target)  )

```



```{r }
getSamleOfMixClassesTsne( 1000 , 2 , maxDim = 2 ) %>% ggplot( aes( x = V1, y = V2 ) ) + geom_point( aes( colour = target)  )

```



```{r }
getSamleOfMixClassesTsne( 1000 , 3 , maxDim = 2 ) %>% ggplot( aes( x = V1, y = V2 ) ) + geom_point( aes( colour = target)  )

```


3D plot

```{r }

getSamleOfMixClassesTsne( 1000 , 1, maxDim = 3 ) %>% scatterPlot3DDimReduction()



```


```{r }

getSamleOfMixClassesTsne( 1000 , 2, maxDim = 3 ) %>% scatterPlot3DDimReduction()



```

```{r }

getSamleOfMixClassesTsne( 1000 , 3, maxDim = 3 ) %>% scatterPlot3DDimReduction()



```


In the above 3d graphs we were checking if we visually we can see any clusters, or any way to separate the red and white points,
it looks not easy at 3D dimension,
we will now apply some neural network model, to predict the class of the wave, we can use to train the models and validate them:
- Directly the 'melfcc' matrices
- Reduced dimensions using of Tsne transformation




# Machine learning

## Deep learning with keras


we check keras installation

we have 3 waves, and every wave needs 19 x 64 matrix, and we have a total 560000 rows

19 x 64 x 3 will be the input format of neural network,

we build a function that can convert any set of waves to the input of our neural network,
it takes as paramters the number of waves that we want to convert, then it will take a samples of that number of waves randomly
it transform every wave to a matrix of 19 x 64

```{r }

convertToNeuralInputShape <- function( numberSamples) {

  "../machineLearningData/gravitationalWaves/train/file_labels.csv" %>%
    getListOfWaves() %>%
    sample_n( size = numberSamples ) %>%
    select(-X) %>%
    select(filePath) %>%
    unlist() %>%
    as.character() %>%
    lapply(
      function(path) {
        wave1 <- path %>%
          readWaveFromNpy(1)  %>%
          calCulateMFCCMatrix( ncep = 19,wl = 64, fbtype="htkmel" , dcttype="t3" )
        wave2 <- path %>%
          readWaveFromNpy(2) %>%
          calCulateMFCCMatrix( ncep = 19,wl = 64, fbtype="htkmel" , dcttype="t3" )
        wave3 <- path %>%
          readWaveFromNpy(3) %>%
          calCulateMFCCMatrix( ncep = 19,wl = 64, fbtype="htkmel" , dcttype="t3" )

        cbind(wave1,wave2,wave3) %>% array(c(19,64,3))

      } ) %>%
    array(c(numberSamples,19,64,3))

}

```


let's measure the size of resulted matrix for every wave:

```{r }
convertToNeuralInputShape(1)%>% utils::object.size( ) %>% format('Mb')

```

so, 560 000 waves will need: 6 x 10^13 bytes ->  60 TeraBytes, this is very high to hold in memory and train the neural network,

to solve the problem we will need a kind of data streaming, to read not all the data, but smaller amounts and loop on them util we finish the learning

Keras hopefully has such way of learning by loading smaller chuncks of training data 'keras::fit_generator'

[python example](https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)
Good explanation for [r example](https://keras.rstudio.com/articles/faq.html#how-can-i-use-keras-with-datasets-that-dont-fit-in-memory)
[r example](https://stackoverflow.com/questions/53357901/using-a-custom-r-generator-function-with-fit-generator-keras-r)


To start the neural network model, we will copy [start_example](https://github.com/rstudio/keras/blob/master/vignettes/examples/cifar10_cnn.R)
we change its input to adapt it to the output of our function calculating MELFCC function 19x63 or 19x63x3 depending on of we use the 3 signals, or only one
the output of the network will be 1 dense layer finishing with softmax activation,

two ways to model that we can see for the moment:
- use three independent models, every one will be trained by one wave, at the end we bring them together using ensemble
- use one model, that we train by the three signals of the three stations




```{r }

modelWave1 <- trainWith1Wave( waveIndex = 1)
modelWave2 <- trainWith1Wave( waveIndex = 2)
modelWave3 <- trainWith1Wave( waveIndex = 3)


```


```{r }






```
